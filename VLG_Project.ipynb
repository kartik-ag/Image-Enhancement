{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DHa8S6MxUvB8"
      },
      "outputs": [],
      "source": [
        "# src/data_generator.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, noisy_dir, clean_dir, batch_size=32, img_size=(256, 256)):\n",
        "        self.noisy_dir = noisy_dir\n",
        "        self.clean_dir = clean_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.noisy_files = os.listdir(self.noisy_dir)\n",
        "        self.clean_files = os.listdir(self.clean_dir)\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.noisy_files) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_noisy = self.noisy_files[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_clean = self.clean_files[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        X, y = self.__data_generation(batch_noisy, batch_clean)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.noisy_files))\n",
        "\n",
        "    def __data_generation(self, batch_noisy, batch_clean):\n",
        "        X = np.empty((self.batch_size, *self.img_size, 3))\n",
        "        y = np.empty((self.batch_size, *self.img_size, 3))\n",
        "\n",
        "        for i, (noisy_file, clean_file) in enumerate(zip(batch_noisy, batch_clean)):\n",
        "            noisy_img = load_img(os.path.join(self.noisy_dir, noisy_file), target_size=self.img_size)\n",
        "            clean_img = load_img(os.path.join(self.clean_dir, clean_file), target_size=self.img_size)\n",
        "\n",
        "            X[i,] = img_to_array(noisy_img) / 255.0\n",
        "            y[i,] = img_to_array(clean_img) / 255.0\n",
        "\n",
        "        return X, y\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# src/mirnet_model.py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, Add\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def residual_block(x, filters, kernel_size=3, stride=1):\n",
        "    res = Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
        "    res = ReLU()(res)\n",
        "    res = Conv2D(filters, kernel_size, strides=stride, padding='same')(res)\n",
        "    return Add()([x, res])\n",
        "\n",
        "def mirnet_model(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(inputs)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    for _ in range(3):  # You can adjust the number of residual blocks\n",
        "        x = residual_block(x, 64)\n",
        "\n",
        "    x = Conv2D(3, (3, 3), padding='same')(x)\n",
        "    outputs = Add()([inputs, x])\n",
        "\n",
        "    return Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "P4dM2o9ZU6Ea"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import gc\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Define custom MSE loss function\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return K.mean(K.square(y_pred - y_true), axis=-1)\n",
        "\n",
        "# Paths to the data directories in Google Drive\n",
        "data_dir = '/content/drive/MyDrive/dataset'  # Adjust this path if necessary\n",
        "\n",
        "noisy_train_dir = os.path.join(data_dir, 'train', 'low')\n",
        "clean_train_dir = os.path.join(data_dir, 'train', 'high')\n",
        "noisy_val_dir = os.path.join(data_dir, 'val', 'low')\n",
        "clean_val_dir = os.path.join(data_dir, 'val', 'high')\n",
        "noisy_test_dir = os.path.join(data_dir, 'test', 'low')\n",
        "clean_test_dir = os.path.join(data_dir, 'test', 'high')\n",
        "\n",
        "batch_size = 32\n",
        "img_size = (128, 128)\n",
        "epochs = 150\n",
        "\n",
        "# Create data generators\n",
        "train_generator = DataGenerator(noisy_train_dir, clean_train_dir, batch_size=batch_size, img_size=img_size)\n",
        "val_generator = DataGenerator(noisy_val_dir, clean_val_dir, batch_size=batch_size, img_size=img_size)\n",
        "test_generator = DataGenerator(noisy_test_dir, clean_test_dir, batch_size=batch_size, img_size=img_size)\n",
        "\n",
        "# Define input shape based on image size\n",
        "input_shape = (*img_size, 3)\n",
        "\n",
        "# Create and compile MIRNet model\n",
        "model = mirnet_model(input_shape)\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss=mse_loss, metrics=['mae'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, validation_data=val_generator, epochs=epochs, verbose=1)\n",
        "\n",
        "# Optimized evaluate_model function\n",
        "def evaluate_model(generator):\n",
        "    total_psnr = 0.0\n",
        "    total_loss = 0.0\n",
        "    total_batches = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_batch_ys = []\n",
        "\n",
        "    # Iterate through the generator to get all predictions and ground truth\n",
        "    for batch_x, batch_y in generator:\n",
        "        preds = model.predict(batch_x, verbose=0)\n",
        "        all_preds.append(preds)\n",
        "        all_batch_ys.append(batch_y)\n",
        "        total_batches += 1\n",
        "        print(f'Processed batch {total_batches}')\n",
        "        gc.collect()  # Explicitly invoke garbage collection\n",
        "\n",
        "    # Concatenate all batches\n",
        "    all_preds = np.concatenate(all_preds, axis=0)\n",
        "    all_batch_ys = np.concatenate(all_batch_ys, axis=0)\n",
        "    print('Concatenation complete')\n",
        "\n",
        "    # # Calculate PSNR for the entire dataset\n",
        "    psnr_values = [psnr(all_batch_ys[i], all_preds[i], data_range=all_batch_ys[i].max() - all_batch_ys[i].min()) for i in range(len(all_batch_ys))]\n",
        "    avg_psnr = np.mean(psnr_values)\n",
        "    print(f'PSNR calculation complete: {avg_psnr}')\n",
        "\n",
        "    # Calculate loss for the entire dataset\n",
        "    total_loss = model.evaluate(all_preds, all_batch_ys, verbose=0)[0]  # Assuming first element is loss\n",
        "    print('Loss evaluation complete')\n",
        "\n",
        "    return total_loss, avg_psnr\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_psnr = evaluate_model(test_generator)\n",
        "print(f'Test Loss: {test_loss}, Test PSNR: {test_psnr}')\n",
        "\n",
        "# Save the model after training\n",
        "model.save('mirnet_model_trained.h5')\n",
        "print('Model saved successfully')\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('/content/mirnet_model_trained.h5', custom_objects={'mse_loss': mse_loss})\n",
        "print('Model loaded successfully')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKQr6rrRZ3AA",
        "outputId": "40af1ea8-0140-46a1-a564-4b9eb4a09a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 128, 128, 64)         1792      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 128, 128, 64)         0         ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 64)         36928     ['re_lu[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)              (None, 128, 128, 64)         0         ['conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 128, 128, 64)         36928     ['re_lu_1[0][0]']             \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 128, 128, 64)         0         ['re_lu[0][0]',               \n",
            "                                                                     'conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 128, 128, 64)         36928     ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)              (None, 128, 128, 64)         0         ['conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 128, 128, 64)         36928     ['re_lu_2[0][0]']             \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 128, 128, 64)         0         ['add[0][0]',                 \n",
            "                                                                     'conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 128, 128, 64)         36928     ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)              (None, 128, 128, 64)         0         ['conv2d_5[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 128, 128, 64)         36928     ['re_lu_3[0][0]']             \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 128, 128, 64)         0         ['add_1[0][0]',               \n",
            "                                                                     'conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 128, 128, 3)          1731      ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 128, 128, 3)          0         ['input_1[0][0]',             \n",
            "                                                                     'conv2d_7[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 225091 (879.26 KB)\n",
            "Trainable params: 225091 (879.26 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/150\n",
            "10/10 [==============================] - 137s 14s/step - loss: 0.1968 - mae: 0.3847 - val_loss: 0.1358 - val_mae: 0.2930\n",
            "Epoch 2/150\n",
            "10/10 [==============================] - 23s 2s/step - loss: 0.1378 - mae: 0.2974 - val_loss: 0.1301 - val_mae: 0.2441\n",
            "Epoch 3/150\n",
            "10/10 [==============================] - 23s 2s/step - loss: 0.1061 - mae: 0.2529 - val_loss: 0.0854 - val_mae: 0.2103\n",
            "Epoch 4/150\n",
            "10/10 [==============================] - 23s 2s/step - loss: 0.0691 - mae: 0.2106 - val_loss: 0.0649 - val_mae: 0.1960\n",
            "Epoch 5/150\n",
            "10/10 [==============================] - 23s 2s/step - loss: 0.0629 - mae: 0.2040 - val_loss: 0.0558 - val_mae: 0.1874\n",
            "Epoch 6/150\n",
            "10/10 [==============================] - 23s 2s/step - loss: 0.0580 - mae: 0.1961 - val_loss: 0.0532 - val_mae: 0.1836\n",
            "Epoch 7/150\n",
            "10/10 [==============================] - 23s 2s/step - loss: 0.0552 - mae: 0.1941 - val_loss: 0.0511 - val_mae: 0.1795\n",
            "Epoch 8/150\n",
            "10/10 [==============================] - 23s 2s/step - loss: 0.0542 - mae: 0.1916 - val_loss: 0.0500 - val_mae: 0.1788\n",
            "Epoch 9/150\n",
            "10/10 [==============================] - 23s 2s/step - loss: 0.0538 - mae: 0.1908 - val_loss: 0.0498 - val_mae: 0.1794\n",
            "Epoch 10/150\n",
            "10/10 [==============================] - 23s 2s/step - loss: 0.0529 - mae: 0.1895 - val_loss: 0.0494 - val_mae: 0.1783\n",
            "Epoch 11/150\n",
            " 6/10 [=================>............] - ETA: 7s - loss: 0.0483 - mae: 0.1814"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate_model.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Define custom MSE loss function\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return K.mean(K.square(y_pred - y_true), axis=-1)\n",
        "\n",
        "# Paths and parameters\n",
        "data_dir = '/content/drive/MyDrive/dataset'\n",
        "noisy_val_dir = os.path.join(data_dir, 'val', 'low')\n",
        "clean_val_dir = os.path.join(data_dir, 'val', 'high')\n",
        "img_size = (128, 128)\n",
        "batch_size =\n",
        "\n",
        "# Load trained model\n",
        "model = load_model('/content/mirnet_model_trained.h5', custom_objects={'mse_loss': mse_loss})\n",
        "\n",
        "# Create data generator for validation set\n",
        "val_generator = DataGenerator(noisy_val_dir, clean_val_dir, batch_size=batch_size, img_size=img_size)\n",
        "\n",
        "# Evaluate model on validation set\n",
        "val_loss = model.evaluate(val_generator)\n",
        "print(f'Validation Loss: {val_loss}')\n",
        "\n",
        "# Visualize example denoising results\n",
        "def visualize_denoising(model, val_generator, num_samples=4):  # Ensure num_samples is not greater than batch_size\n",
        "    noisy_images, clean_images = val_generator[0]  # Assuming batch size of 8, take first batch\n",
        "    denoised_images = model.predict(noisy_images)\n",
        "\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    for i in range(num_samples):\n",
        "        plt.subplot(3, num_samples, i + 1)\n",
        "        plt.imshow(np.clip(noisy_images[i], 0, 1))  # Clip values to [0, 1] for visualization\n",
        "        plt.title('Noisy')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(3, num_samples, num_samples + i + 1)\n",
        "        plt.imshow(np.clip(denoised_images[i], 0, 1))  # Clip values to [0, 1] for visualization\n",
        "        plt.title('Denoised')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(3, num_samples, 2 * num_samples + i + 1)\n",
        "        plt.imshow(np.clip(clean_images[i], 0, 1))  # Clip values to [0, 1] for visualization\n",
        "        plt.title('Clean')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize denoising results\n",
        "visualize_denoising(model, val_generator)\n"
      ],
      "metadata": {
        "id": "7qQ2utyflEHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate_model.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Define custom MSE loss function\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return K.mean(K.square(y_pred - y_true), axis=-1)\n",
        "\n",
        "# Paths and parameters\n",
        "data_dir = '/content/drive/MyDrive/dataset'\n",
        "noisy_val_dir = os.path.join(data_dir, 'test', 'low')\n",
        "clean_val_dir = os.path.join(data_dir, 'test', 'high')\n",
        "img_size = (128, 128)\n",
        "batch_size = 4\n",
        "\n",
        "# Load trained model\n",
        "model = load_model('/content/mirnet_model_trained.h5', custom_objects={'mse_loss': mse_loss})\n",
        "\n",
        "# Create data generator for validation set\n",
        "val_generator = DataGenerator(noisy_val_dir, clean_val_dir, batch_size=batch_size, img_size=img_size)\n",
        "\n",
        "# Evaluate model on validation set\n",
        "val_loss = model.evaluate(val_generator)\n",
        "print(f'Validation Loss: {val_loss}')\n",
        "\n",
        "# Visualize example denoising results\n",
        "def visualize_denoising(model, val_generator, num_samples=4):  # Ensure num_samples is not greater than batch_size\n",
        "    noisy_images, clean_images = val_generator[0]  # Assuming batch size of 8, take first batch\n",
        "    denoised_images = model.predict(noisy_images)\n",
        "\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    for i in range(num_samples):\n",
        "        plt.subplot(3, num_samples, i + 1)\n",
        "        plt.imshow(np.clip(noisy_images[i], 0, 1))  # Clip values to [0, 1] for visualization\n",
        "        plt.title('Noisy')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(3, num_samples, num_samples + i + 1)\n",
        "        plt.imshow(np.clip(denoised_images[i], 0, 1))  # Clip values to [0, 1] for visualization\n",
        "        plt.title('Denoised')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(3, num_samples, 2 * num_samples + i + 1)\n",
        "        plt.imshow(np.clip(clean_images[i], 0, 1))  # Clip values to [0, 1] for visualization\n",
        "        plt.title('Clean')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize denoising results\n",
        "visualize_denoising(model, val_generator)\n"
      ],
      "metadata": {
        "id": "4zyY-6IPnUpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# denoise_image.py\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('/content/mirnet_model_trained.h5', custom_objects={'mse_loss': mse_loss})\n",
        "\n",
        "# Function to load and preprocess an image\n",
        "def load_and_preprocess_image(image_path, img_size):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, img_size)\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "    return image\n",
        "\n",
        "# Path to the noisy image\n",
        "noisy_image_path = '/content/image3.jpg'\n",
        "img_size = (128, 128)\n",
        "\n",
        "# Load and preprocess the noisy image\n",
        "noisy_image = load_and_preprocess_image(noisy_image_path, img_size)\n",
        "input_image = np.expand_dims(noisy_image, axis=0)\n",
        "\n",
        "# Use the model to denoise the image\n",
        "denoised_image = model.predict(input_image)\n",
        "denoised_image = np.squeeze(denoised_image, axis=0)\n",
        "denoised_image = (denoised_image * 255).astype(np.uint8)\n",
        "denoised_image = cv2.cvtColor(denoised_image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "# Save the denoised image\n",
        "cv2.imwrite('denoised_image.jpg', denoised_image)\n",
        "\n"
      ],
      "metadata": {
        "id": "oVvn4KM6n6Nj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}